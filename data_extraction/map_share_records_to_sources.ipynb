{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each source below, create a file containing IDs of the records present in both SHARE and that source.\n",
    "\n",
    "** basically do an inner join between SHARE and each source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "SHARE_FILE = os.path.join('..', '..', 'data', 'share-jan-2019.json')\n",
    "\n",
    "OUTPUT_FOLDER = os.path.join('..', '..', 'data', 'share_source_ids')\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.mkdir(OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(ids, source_name):\n",
    "    with open(os.path.join(OUTPUT_FOLDER, source_name + '.txt'), 'w') as o:\n",
    "        for id_ in ids:\n",
    "            o.write(id_ + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OSF PREPRINT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSF_PREPRINT_FILE = os.path.join('..', '..', 'raw_data', 'osf.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21186 ids in common.\n",
      "40 ids in SHARE but not in OSF Preprint API data.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "osf_ids = set() #using a set in case there are any duplicate ids\n",
    "with open(OSF_PREPRINT_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        for record in data['data']:\n",
    "            osf_ids.add(record['id'])\n",
    "\n",
    "share_osf_ids = set()\n",
    "with open(SHARE_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        for identifier in data['identifiers']:\n",
    "            if identifier.startswith('http://osf.io/'):\n",
    "                id_ = identifier.replace('http://osf.io/', '')\n",
    "                if id_.endswith('/'):\n",
    "                    id_ = id_[:-1]\n",
    "                \n",
    "                share_osf_ids.add(id_)   \n",
    "\n",
    "ids_in_common = osf_ids.intersection(share_osf_ids)\n",
    "print('{} ids in common.'.format(len(ids_in_common)))\n",
    "print('{} ids in SHARE but not in OSF Preprint API data.'.format(len(share_osf_ids - osf_ids)))\n",
    "\n",
    "save_to_file(ids_in_common, 'osf_preprint_api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3q5if',\n",
       " '3x2nc',\n",
       " '3ygkq',\n",
       " '6p2ws',\n",
       " '6vpjm',\n",
       " '74dte',\n",
       " '7bsp4',\n",
       " '7tc6p',\n",
       " '8krmb',\n",
       " '92xts',\n",
       " 'b5j3w',\n",
       " 'dgmzf',\n",
       " 'envb7',\n",
       " 'g7vry',\n",
       " 'gcnmj',\n",
       " 'hvzej',\n",
       " 'j2abz',\n",
       " 'kfv2h',\n",
       " 'phjxg',\n",
       " 'preprints/engrxiv/s47fh',\n",
       " 'preprints/psyarxiv/4dcw6',\n",
       " 'preprints/psyarxiv/98v3f',\n",
       " 'preprints/psyarxiv/jkc4n',\n",
       " 'preprints/psyarxiv/n4yy2',\n",
       " 'preprints/psyarxiv/zzbka',\n",
       " 'preprints/socarxiv/d67x5',\n",
       " 'preprints/socarxiv/vuhhp',\n",
       " 'q2x87',\n",
       " 'qjuky',\n",
       " 'qtu37',\n",
       " 'r4nmy',\n",
       " 's2kym',\n",
       " 'tgez8',\n",
       " 'ufjwv',\n",
       " 'uh5c8',\n",
       " 'urxqs',\n",
       " 'xtavb',\n",
       " 'ys5jk',\n",
       " 'ytc5d',\n",
       " 'z4knb'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share_osf_ids - osf_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arXiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARXIV_FOLDER = os.path.join('..', '..', 'raw_data', 'arXiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1301577 ids in common.\n",
      "0 ids in SHARE but not in arXiv data.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET, csv\n",
    "\n",
    "arxiv_files = os.listdir(ARXIV_FOLDER)\n",
    "if '.DS_Store' in arxiv_files:\n",
    "    arxiv_files.remove('.DS_Store')\n",
    "    \n",
    "namespaces = {'oai' : 'http://www.openarchives.org/OAI/2.0/',\n",
    "              'arxiv' : 'http://arxiv.org/OAI/arXiv/'}\n",
    "\n",
    "arxiv_ids = set()\n",
    "for arxiv_file in arxiv_files:\n",
    "    root = ET.parse(os.path.join(ARXIV_FOLDER, arxiv_file))\n",
    "\n",
    "    for record in root.findall('oai:ListRecords/oai:record', namespaces):\n",
    "        arxiv_ids.add(record.find('oai:header/oai:identifier', namespaces).text.replace('oai:arXiv.org:', ''))\n",
    "\n",
    "share_arxiv_ids = set()\n",
    "with open(SHARE_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        for identifier in data['identifiers']:\n",
    "            if identifier.startswith('http://arxiv.org/abs/'):\n",
    "                id_ = identifier.replace('http://arxiv.org/abs/', '')\n",
    "                if id_.endswith('/'):\n",
    "                    id_ = id_[:-1]\n",
    "                if id_[-2] == 'v' and id_[-1].isdigit():\n",
    "                    id_ = id_[:-2]\n",
    "                if id_[-3] == 'v' and id_[-2].isdigit() and id_[-1].isdigit():\n",
    "                    id_ = id_[:-3]\n",
    "                    \n",
    "                share_arxiv_ids.add(id_)\n",
    "                \n",
    "ids_in_common = arxiv_ids.intersection(share_arxiv_ids)\n",
    "print('{} ids in common.'.format(len(ids_in_common)))\n",
    "print('{} ids in SHARE but not in arXiv data.'.format(len(share_arxiv_ids - arxiv_ids)))\n",
    "\n",
    "save_to_file(ids_in_common, 'arxiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share_arxiv_ids - arxiv_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CrossRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROSSREF_FILE = os.path.join('..', '..', 'raw_data', 'CrossRef.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62839 ids in common.\n",
      "681886 ids in SHARE but not in CrossRef.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "crossref_ids = set() #using a set in case there are any duplicate ids\n",
    "with open(CROSSREF_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        crossref_ids.add(data['DOI'])\n",
    "\n",
    "share_crossref_ids = set()\n",
    "with open(SHARE_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        for identifier in data['identifiers']:\n",
    "            if identifier.startswith('http://dx.doi.org/'):\n",
    "                id_ = identifier.replace('http://dx.doi.org/', '')\n",
    "                if id_.endswith('/'):\n",
    "                    id_ = id_[:-1]\n",
    "                \n",
    "                share_crossref_ids.add(id_.lower()) \n",
    "                \n",
    "            if identifier.startswith('http://doi.org/'):\n",
    "                id_ = identifier.replace('http://doi.org/', '')\n",
    "                if id_.endswith('/'):\n",
    "                    id_ = id_[:-1]\n",
    "                    \n",
    "                share_crossref_ids.add(id_.lower())\n",
    "\n",
    "ids_in_common = crossref_ids.intersection(share_crossref_ids)\n",
    "print('{} ids in common.'.format(len(ids_in_common)))\n",
    "print('{} ids in SHARE but not in CrossRef.'.format(len(share_crossref_ids - crossref_ids)))\n",
    "\n",
    "save_to_file(ids_in_common, 'crossref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
